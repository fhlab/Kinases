{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load up the sequencing counts produced by proteins.py\n",
    "* Combine data from two sequencing gates\n",
    "* Take input FASTA files\n",
    "* Perform needle alignment for input files\n",
    "* Retrieve counts from sequencing for those variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the initialization and imports\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import math\n",
    "import pprint\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns   This is just for plots\n",
    "\n",
    "from Bio import SeqIO, AlignIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Emboss.Applications import NeedleallCommandline\n",
    "\n",
    "# Demand Python 3.\n",
    "if sys.version_info[0] < 3:\n",
    "    print(\"Python 3 is required, but you are using Python %i.%i.%i\") % (\n",
    "        sys.version_info[0], sys.version_info[1], sys.version_info[2])\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell specifies where the InDelScanner scripts are located: modify `indels_path` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the specific functions from ind and proteins.py\n",
    "indels_path=\"/home/maya/InDelScanner/indels\"  # /PATH/TO/InDelScanner\n",
    "if indels_path not in sys.path:\n",
    "    sys.path.append(indels_path)\n",
<<<<<<< HEAD:Retrieve_individual_clones.ipynb
    "from indels.ind import trim_read, findEnds, endMatch, findGap, gapAlign\n",
    "from indels.proteins import protein_needle, indel_len, find_protein_short"
=======
    "from indels.ind import trim_read, findEnds, endMatch, findGap #, gapAlign\n",
    "from indels.composition import find_dna_diff, find_dna_hgvs, find_protein_diff\n",
    "from indels.proteins import protein_needle, find_protein_short"
>>>>>>> master:Individual_variant_analysis.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results specific to MEK1 protein libraries: interrogating the sequencing counts\n",
    "\n",
    "Change directory to where the sequencing count dictionaries are located, load them and combine counts to get the `mek` Counter containing sequencing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/c/Users/Maya/Dropbox/mek_results\")\n",
    "\n",
    "with open('mek_counter.pickle', 'rb') as f:\n",
    "    mek = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from individually sequenced clones\n",
    "def retrieve_ind_clones(mek, filename, outfile):\n",
    "    \n",
    "    variants = []\n",
    "\n",
    "    columns = ['Sample', 'Protein'] + list(mek.keys())\n",
    "\n",
    "    with open(outfile, 'w') as f:\n",
    "        writer = csv.DictWriter(f, delimiter=',', fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for pair in AlignIO.parse(filename, \"fasta\", seq_count=2):\n",
    "            # both read and ref are MutableSeq\n",
    "            ref = str(pair[0].seq)\n",
    "            read = str(pair[1].seq)\n",
    "            readname = pair[1].id\n",
    "            print(readname)\n",
    "\n",
    "            ref, read = trim_read(ref, read)\n",
    "\n",
    "            # check that there is no frame shift or gross mistranslation\n",
    "            ends = findEnds(read, ref, 0)\n",
    "            if not endMatch(read, ref, ends, 2):\n",
    "                continue\n",
    "\n",
    "            protein = find_protein_short(read, ref, ends)\n",
    "            print(protein)\n",
    "            variants.append(protein)\n",
    "            row = {'Sample': readname, 'Protein': protein}\n",
    "            for fraction in mek.keys():\n",
    "                row[fraction] = mek[fraction][protein]\n",
    "\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        \n",
    "    return variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD:Retrieve_individual_clones.ipynb
    "aln_file = protein_needle(['Lib1-10.fa'], 'Xref.fa')"
=======
    "protein_needle(['table1.fa'], 'Xref.fa')"
>>>>>>> master:Individual_variant_analysis.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Retrieve_individual_clones.ipynb
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lib1\n",
      "6L/7aI/8aA/9L/11F/13M\n",
      "Lib2\n",
      "6F/7aP/9W/11L/13M\n",
      "Lib3\n",
      "6L/7aF/9L/11I/13I\n",
      "Lib4\n",
      "6A/7aI/8aA/9L/11L/13I\n",
      "Lib5\n",
      "6W/7aI/9F/11L/13V\n",
      "Lib6\n",
      "6A/7aP/8aA/9L/11V/13W\n",
      "Lib7\n",
      "6L/7aI/8aA/9M/11W/13W\n",
      "Lib8\n",
      "6V/7aP/8aA/9F/11F/13M\n",
      "Lib9\n",
      "6A/7aK/9L/11L/13W\n",
      "Lib10\n",
      "6A/7aI/8aA/9L/11V/13M\n",
      "WT\n",
      "6P/9I/11L/13P\n",
      "ILAA\n",
      "6P/9A/11A/13P\n",
      "Consensus\n",
      "6L/7aL/9L/11L/13I\n"
     ]
    }
   ],
   "source": [
    "variants = retrieve_ind_clones(mek, 'Lib1-10.aln', 'single_sub.csv')"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_ind_clones(mek, 'table1.aln', 'table1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTE single variants for TRIAD manuscript\n",
    "\n",
    "Adapted from `sanger.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/c/Users/Maya/Dropbox/PTE_sanger/results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print mutations present in a list of clones\n",
    "def print_Sanger_variants(alnfile, outfile, start_offset=6, end_trail=6, debug=False, refname='PTE-R0'):\n",
    "    \n",
    "    columns = ['Sample', 'DNA_hgvs', 'Protein_short', 'Protein_tuple', 'DNA_tuple']\n",
    "    \n",
    "    with open(outfile, 'w', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, delimiter=',', fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for pair in AlignIO.parse(alnfile, \"fasta\", seq_count=2):\n",
    "            # both read and ref are MutableSeq\n",
    "            ref = pair[0].seq.tomutable()\n",
    "            read = pair[1].seq.tomutable()\n",
    "            readname = pair[1].id\n",
    "            ref, read = trim_read(ref, read)\n",
    "            \n",
    "            ends = findEnds(read, ref, 0)\n",
    "            if not endMatch(read, ref, ends, 2):\n",
    "                print(readname, 'ends not match')\n",
    "                continue\n",
    "\n",
    "            dna_errors, dna_hgvs, prot_errors, prot_short = None, None, None, None\n",
    "            # after setting the blank values, look for mutations\n",
    "            dna_errors = find_dna_diff(read, ref, debug, start_offset, end_trail)  # errors = a tuple\n",
    "            dna_hgvs = find_dna_hgvs(read, ref, refname, debug, start_offset, end_trail)  # string in HGVS format (ish)\n",
    "            prot_errors, prot_short = find_protein_diff(read, ref, debug, start_offset, end_trail)\n",
    "\n",
    "                \n",
    "            row = {'Sample': readname, 'DNA_hgvs': dna_hgvs, 'Protein_short': prot_short, \n",
    "                   'Protein_tuple': prot_errors, 'DNA_tuple': dna_errors}\n",
    "            writer.writerow(row)\n",
    "\n",
    "print_Sanger_variants('PTE_plate1_filtered.aln', 'PTE_plate1.csv')\n",
    "print_Sanger_variants('PTE_plate2_filtered.aln', 'PTE_plate2.csv')"
>>>>>>> master:Individual_variant_analysis.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Retrieve_individual_clones.ipynb
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6L/7aI/8aA/9L/11F/13M',\n",
       " '6F/7aP/9W/11L/13M',\n",
       " '6L/7aF/9L/11I/13I',\n",
       " '6A/7aI/8aA/9L/11L/13I',\n",
       " '6W/7aI/9F/11L/13V',\n",
       " '6A/7aP/8aA/9L/11V/13W',\n",
       " '6L/7aI/8aA/9M/11W/13W',\n",
       " '6V/7aP/8aA/9F/11F/13M',\n",
       " '6A/7aK/9L/11L/13W',\n",
       " '6A/7aI/8aA/9L/11V/13M',\n",
       " '6P/9I/11L/13P',\n",
       " '6P/9A/11A/13P',\n",
       " '6L/7aL/9L/11L/13I']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_Sanger_variants('PTE_plate1_filtered.aln', 'PTE_plate1.csv')"
>>>>>>> master:Individual_variant_analysis.ipynb
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

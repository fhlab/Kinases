{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the initialization and imports\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import math\n",
    "import pprint\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from Bio import SeqIO, AlignIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Emboss.Applications import NeedleallCommandline\n",
    "\n",
    "# Demand Python 3.\n",
    "if sys.version_info[0] < 3:\n",
    "    print(\"Python 3 is required, but you are using Python %i.%i.%i\") % (\n",
    "        sys.version_info[0], sys.version_info[1], sys.version_info[2])\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the specific functions from ind and proteins.py\n",
    "indels_path=\"/home/mp/InDelScanner\"  # /PATH/TO/InDelScanner\n",
    "if indels_path not in sys.path:\n",
    "    sys.path.append(indels_path)\n",
    "from indels.ind import trim_read, findEnds, endMatch, findGap, gapAlign\n",
    "from ipynb.fs.defs.Library_diversity import convert_variant_to_dict, single_fraction_enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/c/Users/Maya/Documents/03_Kinases/\")\n",
    "\n",
    "with open('mek.pickle', 'rb') as f:\n",
    "    mek = pickle.load(f)\n",
    "\n",
    "with open('kinases_all_ref.pickle', 'rb') as f:\n",
    "    all_ref = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general restrictions stemming from SpliMLib library design\n",
    "aa_2 = ['A', 'Δ']\n",
    "aa_12 = ['A','G','P','Y','D','K','M','V','I','L','F','W']\n",
    "aa_13 = aa_12 +  ['Δ']\n",
    "splimlib = {'6': aa_12, '9': aa_12, '11': aa_12, '13': aa_12, '7a': aa_13, '8a': aa_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame.from_dict(mek).fillna(0).sort_values(by=['high', 'med','low-t'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the dataset: collect SpliMLiB variants with >10/5/3 reads in H/M/L gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_short = '6P/9I/11L/13P'\n",
    "wt = {'6': 'P', '7a': 'Δ', '8a': 'Δ', '9': 'I', '11': 'L', '13': 'P'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[(lambda df_all: df_all['high'] >= 10) or (lambda df_all: df_all['med'] >= 5) or (lambda df_all: df_all['low-t'] >= 3), :].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all variants that appear in the Venn circle diagram: 10+ reads in high gate OR 5+ in medium OR 3+ in low gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df_all.loc[lambda df: df['low-t'] >= 3, :]\n",
    "m = df_all.loc[lambda df: df['med'] >= 5, :]\n",
    "h = df_all.loc[lambda df: df['high'] >= 10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_df = pd.concat([h, m, l], join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_short = '6P/9I/11L/13P'\n",
    "wt = {'6': 'P', '7a': 'Δ', '8a': 'Δ', '9': 'I', '11': 'L', '13': 'P'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Hamming distance for variants vs WT in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming distance = 0 if the aa matches at all positions\n",
    "def hamming_distance(s1, s2, splimlib):\n",
    "    d = 0\n",
    "    if (len(s1) != len(splimlib)) or (len(s2) != len(splimlib)):\n",
    "        d += 1\n",
    "\n",
    "    for p in splimlib.keys():\n",
    "        if s1[p] != s2[p]:\n",
    "            d += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_dist = {}\n",
    "for n in all_filtered_df.index:\n",
    "    s1 = convert_variant_to_dict(n)\n",
    "    H_dist[n] = hamming_distance(wt, s1, splimlib)\n",
    "    \n",
    "all_filtered_df['Hamming'] = pd.Series(H_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we are only considering variants that fit the expected SpliMLiB pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_variant_in_expected_set(m_by_pos, splimlib):\n",
    "    for k, a in m_by_pos.items():\n",
    "        if k not in splimlib.keys():\n",
    "            return False\n",
    "        elif a not in splimlib[k]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations_all_positions = {}\n",
    "position_order = ['6', '7a', '8a', '9', '11', '13']\n",
    "expected = {}\n",
    "\n",
    "for n in all_filtered_df.index:\n",
    "    s1 = convert_variant_to_dict(n)\n",
    "    expected[n] = is_variant_in_expected_set(s1, splimlib)\n",
    "    aa_seq = [p + s1[p] for p in position_order]\n",
    "    mutations_all_positions[n] = '/'.join(aa_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_df['variants'] = pd.Series(mutations_all_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_df['in_lib'] = pd.Series(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splimlib = all_filtered_df.loc[all_filtered_df['in_lib'] == True].drop(columns=['in_lib']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splimlib.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splimlib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splimlib.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the combined enrichment distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the read count data into percentages\n",
    "df = df_splimlib.copy(deep=True)\n",
    "df['total_reads'] = df[['high', 'med', 'low-t']].sum(axis=1)\n",
    "df[['high_per', 'med_per', 'low_per']] = df[['high', 'med', 'low-t']].div(df['total_reads'], axis=0).mul(100).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the variants\n",
    "df = df.sort_values(by=['high_per', 'med_per','low_per'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'index':'variant'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the WT values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_short = '6P/7aΔ/8aΔ/9I/11L/13P'\n",
    "wt = {'6': 'P', '7a': 'Δ', '8a': 'Δ', '9': 'I', '11': 'L', '13': 'P'}\n",
    "df.loc[df['variants'] == wt_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['variants'] == '6P/7aΔ/8aΔ/9A/11A/13P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's check the relationship between the high gate cutoff and the number of active variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_choices = OrderedDict()\n",
    "for i in range(5, 201):\n",
    "    cutoff_choices[i] = len(df.loc[df['high'] >= i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(5, 5))\n",
    "ax.plot(cutoff_choices.keys(), cutoff_choices.values())\n",
    "\n",
    "y_lims = ax.get_ylim()\n",
    "ax.set_ylim([0, y_lims[1]])\n",
    "plt.axvline(x=10, ymin=0, ymax= cutoff_choices[10]/y_lims[1], color='c', label='10+')\n",
    "plt.axvline(x=51, ymin=0, ymax= cutoff_choices[51]/y_lims[1], color='m', label='51+')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylabel('Number of active variants')\n",
    "ax.set_xlabel('Minimum number of reads in high gate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['mediumseagreen', 'gold', 'salmon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 10000\n",
    "n=5\n",
    "\n",
    "fig, axes = plt.subplots(n, 1,figsize=(15,4*n))\n",
    "\n",
    "for p in range(len(axes)):\n",
    "    df[['high_per', 'med_per', 'low_per']].iloc[p*split:(p+1)*split:100].plot.bar(stacked=True, ax=axes[p], color = cols)\n",
    "    axes[p].axes.get_xaxis().set_ticklabels([])\n",
    "    title = 'Every 100th variant, from variant ' + str(p*split) + ' to variant ' + str((p+1)*split)\n",
    "    axes[p].set_title(title, position=(0.5, 0.9))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Read_distribution.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that a variant is truly 'active' decreases going down the plots, with a clear trend:\n",
    "- the top 30K variants have >70% reads in the high gate, thus we can consider them to have good activity against ERK2\n",
    "- after the top 50K (sorted by % reads in high gate), there are <15% reads in high gate. However, there are many variants with a large proportion of reads in the medium gate, which are likely to have WT-like or slightly lower activity.\n",
    "\n",
    "How to proceed? Construct two datasets for analysis:\n",
    "- top: all variants with >70% reads in high gate, regardless of the other bins; this gives 30,534 variants.\n",
    "- high: variants with >30% reads in high gate and few low reads, exact parameters to be determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top = df.loc[df['high_per'] >= 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Top dataset have 30,534 variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.loc[(df['high_per'] < 70) & (df['high_per'] >=30)].sort_values(by=['low_per', 'med_per', 'high_per'], ascending=True)\n",
    "\n",
    "#os = 30000\n",
    "split = 2000\n",
    "n=5\n",
    "\n",
    "fig, axes = plt.subplots(n, 1,figsize=(15,4*n))\n",
    "\n",
    "for p in range(len(axes)):\n",
    "    df_plot[['high_per', 'med_per', 'low_per']].iloc[p*split:(p+1)*split:20].plot.bar(stacked=True, ax=axes[p], color = cols)\n",
    "    #df_plot[['high_per', 'med_per', 'low_per']].iloc[os+p*split:os+(p+1)*split:20].plot.bar(stacked=True, ax=axes[p], color = cols)\n",
    "    \n",
    "    axes[p].axes.get_xaxis().set_ticklabels([])\n",
    "    title = 'Below top dataset: every 20th variant'\n",
    "    axes[p].set_title(title, position=(0.5, 0.9))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, there is no clear cutoff. Still, the variants with <40% reads in the low bin seem to have 50-60% of the reads in the high gate, which is again indicative of strong activity. Thus, define:\n",
    "- high: 70>x>=30 reads in the high gate, <=40% reads in low gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high = df.loc[(df['high_per'] < 70) & (df['high_per'] >=40) & (df['low_per'] <=40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TopTwo dataset (the most likely active, but more borderline variants) contains 5,717 variants.\n",
    "\n",
    "Next, let's look at the oppposite end of the distribution and find the very negative variants, building a Bottom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.loc[df['low_per'] >= 95].sort_values(by=['low_per', 'med_per', 'high_per'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 100000\n",
    "n=3\n",
    "\n",
    "fig, axes = plt.subplots(n, 1,figsize=(15,4*n))\n",
    "\n",
    "for p in range(len(axes)):\n",
    "    df_plot[['high_per', 'med_per', 'low_per']].iloc[p*split:(p+1)*split:1000].plot.bar(stacked=True, ax=axes[p], color = cols)\n",
    "    axes[p].axes.get_xaxis().set_ticklabels([])\n",
    "    title = 'Every 1000th variant, from variant ' + str(p*split) + ' to variant ' + str((p+1)*split)\n",
    "    axes[p].set_title(title, position=(0.5, 0.9))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Read_distribution.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, we have 266,628 variants that are clearly without activity in this assay (95+ percent reads in the low gate; even the negative control variant has 23% in the medium gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilaa_short = '6P/7aΔ/8aΔ/9A/11A/13P'\n",
    "df.loc[df['variants'] == ilaa_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bottom = df.loc[df['low_per'] >= 95].sort_values(by=['low_per', 'med_per', 'high_per'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All: ', len(df_splimlib))\n",
    "print('Top: ', len(df_top))\n",
    "print('High: ', len(df_high))\n",
    "print('Bottom: ', len(df_bottom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have 203,078 variants left to classify. These are going to contain the mostly-negative variants (75%-95% low gate, similar to negative control variant), as well as the in-between medium variants.\n",
    "\n",
    "Next, construct the fourth dataset of mostly-negative variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.loc[(df['low_per'] >= 75) & (df['low_per'] < 95)].sort_values(by=['low_per', 'med_per', 'high_per'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 9000\n",
    "n=7\n",
    "\n",
    "fig, axes = plt.subplots(n, 1,figsize=(15,4*n))\n",
    "\n",
    "for p in range(len(axes)):\n",
    "    df_plot[['high_per', 'med_per', 'low_per']].iloc[p*split:(p+1)*split:100].plot.bar(stacked=True, ax=axes[p], color = cols)\n",
    "    axes[p].axes.get_xaxis().set_ticklabels([])\n",
    "    title = 'Every 100th variant, from variant ' + str(p*split) + ' to variant ' + str((p+1)*split)\n",
    "    axes[p].set_title(title, position=(0.5, 0.9))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Read_distribution.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks reasonable. Now complete the stratification into five sets by labelling the intermediate variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set'] = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['low_per'] >= 95, 'set'] = 'bottom'\n",
    "df.loc[(df['low_per'] >= 75) & (df['low_per'] < 95), 'set'] = 'low'\n",
    "df.loc[df['high_per'] >= 70, 'set'] = 'top'\n",
    "df.loc[(df['high_per'] < 70) & (df['high_per'] >=40) & (df['low_per'] <=40), 'set'] = 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set_numeric'] = 3\n",
    "df.loc[df['low_per'] >= 95, 'set_numeric'] = 1\n",
    "df.loc[(df['low_per'] >= 75) & (df['low_per'] < 95), 'set_numeric'] = 2\n",
    "df.loc[df['high_per'] >= 70, 'set_numeric'] = 5\n",
    "df.loc[(df['high_per'] < 70) & (df['high_per'] >=40) & (df['low_per'] <=40), 'set_numeric'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set'].value_counts().plot(kind='pie')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the distribution of single mutants across this distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = df.loc[(df['Hamming'] == 1)].sort_values(by='set_numeric', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top: ', len(point.loc[(point['set'] == 'top')]))\n",
    "print('High: ', len(point.loc[(point['set'] == 'high')]))\n",
    "print('Medium: ', len(point.loc[(point['set'] == 'medium')]))\n",
    "print('Low: ', len(point.loc[(point['set'] == 'low')]))\n",
    "print('Bottom: ', len(point.loc[(point['set'] == 'bottom')]))\n",
    "print('All: ', len(point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, 57 point mutants relative to MKK1 wt sequence are possible; 53 of these have enough sequencing reads in at least one FACS gate.\n",
    "\n",
    "The WT sequence is in the High set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point.loc[point['set'] == 'top']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top set contains conservative mutations, largely large hydrophobic residues:\n",
    "- 6: I (shifting the Φ-X-Φ motif to the start)\n",
    "- 7a: K (extending the basic pathc) or L (making a L - I - L motif in 7a/9/11)\n",
    "- 8a: Δ (wt) only, indicating that the A insertion is contingent on other reorganisation\n",
    "- 9: P or F, both large and hydrophobic\n",
    "- 11: F or I, both large and hydrophobic\n",
    "- 13: I, W, L, F, all large and hydrophobic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point.loc[point['set'] == 'high']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the high set, which also contains WT, we add:\n",
    "- 11: M, W\n",
    "- 13: V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point.loc[point['set'] == 'medium']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The medium set is the most diverse:\n",
    "- 6: P + W, G, A, Y, V\n",
    "- 7a: Δ + V, M\n",
    "- 8a: Δ + A\n",
    "- 9: I + V, Y, L, M\n",
    "- 11: L + K, V\n",
    "- 13: P + D, K, M, A, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point.loc[point['set'] == 'low']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the low set we see mostly mutations at the start of the D domain, which disrupt the basic patch at the start, while the hydrophobic core is largely intact:\n",
    "- 6: M, L, K, F, D\n",
    "- 7a: I\n",
    "- 8a: \n",
    "- 9: A\n",
    "- 11: P\n",
    "- 13: Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point.loc[point['set'] == 'bottom']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bottom set introduces small or charged amino acids at the three positions that make the core of the Φ-X-Φ motif:\n",
    "- 6: \n",
    "- 7a: P, G, D, F\n",
    "- 8a: \n",
    "- 9: D, G, K, W\n",
    "- 11: A, D, G\n",
    "- 13: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('splimlib.zip')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the initialization and imports\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import math\n",
    "import pprint\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from Bio import SeqIO, AlignIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Emboss.Applications import NeedleallCommandline\n",
    "\n",
    "# Demand Python 3.\n",
    "if sys.version_info[0] < 3:\n",
    "    print(\"Python 3 is required, but you are using Python %i.%i.%i\") % (\n",
    "        sys.version_info[0], sys.version_info[1], sys.version_info[2])\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the specific functions from ind and proteins.py\n",
    "indels_path=\"/home/mp/InDelScanner\"  # /PATH/TO/InDelScanner\n",
    "if indels_path not in sys.path:\n",
    "    sys.path.append(indels_path)\n",
    "from indels.ind import trim_read, findEnds, endMatch, findGap, gapAlign\n",
    "from ipynb.fs.defs.Library_diversity import convert_variant_to_dict, single_fraction_enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/mnt/c/Users/Maya/Documents/03_Kinases/\")\n",
    "\n",
    "with open('mek.pickle', 'rb') as f:\n",
    "    mek = pickle.load(f)\n",
    "\n",
    "with open('kinases_all_ref.pickle', 'rb') as f:\n",
    "    all_ref = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general restrictions stemming from SpliMLib library design\n",
    "aa_2 = ['A', 'Δ']\n",
    "aa_12 = ['A','G','P','Y','D','K','M','V','I','L','F','W']\n",
    "aa_13 = aa_12 +  ['Δ']\n",
    "splimlib = {'6': aa_12, '9': aa_12, '11': aa_12, '13': aa_12, '7a': aa_13, '8a': aa_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the combined enrichment distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame.from_dict(mek).fillna(0).sort_values(by=['high', 'med', 'low-t'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['mediumseagreen', 'gold', 'salmon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 10000\n",
    "n=5\n",
    "\n",
    "fig, axes = plt.subplots(n, 1,figsize=(15,4*n))\n",
    "\n",
    "for p in range(len(axes)):\n",
    "    df_all.iloc[p*split:(p+1)*split:100].plot.bar(stacked=True, ax=axes[p], color = cols)\n",
    "    \n",
    "    axes[p].axes.get_xaxis().set_ticklabels([])\n",
    "    title = 'Every 100th variant, from variant ' + str(p*split) + ' to variant ' + str((p+1)*split)\n",
    "    axes[p].set_title(title, position=(0.5, 0.9))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Read_distribution.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that a variant is truly 'active' decreases going down the plots, with a clear trend:\n",
    "- the top 10K variants are 'active' with a high confidence, the appearance of variants in the medium and low gates is just experimental noise\n",
    "- with some more variability, the same can be said for the next 10-20Ks variants, shown on the second plot. This covers variants with 100+ High reads\n",
    "- looking at the last two plots, there is a high degree of variability in read distribution once we reach <20 reads in high gate. There, further investigation is needed. Two avenues: check the variants from 20K onwards at higher resolution to pin down the cutoff high gate count, and b) take the variants with fewer high counts below that and re-sort according to medium gate distribution. Especially in the less active variants that become the dominant factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = 20000\n",
    "split = 2000\n",
    "n=5\n",
    "\n",
    "fig, axes = plt.subplots(n, 1,figsize=(15,4*n))\n",
    "\n",
    "for p in range(len(axes)):\n",
    "    df_all.iloc[os+p*split:os+(p+1)*split:20].plot.bar(stacked=True, ax=axes[p], color = cols)\n",
    "    \n",
    "    axes[p].axes.get_xaxis().set_ticklabels([])\n",
    "    title = 'Every 20th variant, from variant ' + str(os+p*split) + ' to variant ' + str(os+(p+1)*split)\n",
    "    axes[p].set_title(title, position=(0.5, 0.9))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show that from variant 20K to variant 30K there is increasing variation in the frequencies in medium and low gates. On the whole, the precise activity level for some of the variants is less clear-cut because some are equally or more frequent in the medium gate - are they 'active' and depleted from the sort? Or are they truly less active variants?\n",
    "\n",
    "So, variants with 50+ reads in high gate are 'active'. Let's add some mild filtering to these variants, requiring that the low reads can be <20% of the combined medium + high reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_50p = df_all.loc[(df_all['high'] >= 50) & ((df_all['high']+df_all['med']) > 2*df_all['low-t'])]\n",
    "df_50p.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's try to stratify the distribution in variants below 50 reads in high gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = 30000\n",
    "split = 2000\n",
    "n=3\n",
    "\n",
    "fig, axes = plt.subplots(n, 1,figsize=(15,4*n))\n",
    "\n",
    "for p in range(len(axes)):\n",
    "    df_all.iloc[os+p*split:os+(p+1)*split:20].plot.bar(stacked=True, ax=axes[p], color = cols)\n",
    "    \n",
    "    axes[p].axes.get_xaxis().set_ticklabels([])\n",
    "    title = 'Every 20th variant, from variant ' + str(os+p*split) + ' to variant ' + str(os+(p+1)*split)\n",
    "    axes[p].set_title(title, position=(0.5, 0.9))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below 30 reads in high gate, things are starting to look iffy. Still, there is a proportion of variants with reads only (or nearly only) in high gate.\n",
    "- if the high gate is >10, accept as long as <20% of high+medium gate reads appear in the low gate, and # high gate > # medium gate.Remkes, how many reads in medium gate are okay?\n",
    "\n",
    "So let's pick out those variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20to50 = df_all.loc[(df_all['high'].isin(range(10,50))) & \n",
    "                       (df_all['high'] > df_all['med']) & \n",
    "                       ((df_all['high']+df_all['med']) > 5*df_all['low-t']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20to50.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = 0\n",
    "split = 500\n",
    "n=5\n",
    "\n",
    "fig, axes = plt.subplots(n, 1,figsize=(15,4*n))\n",
    "\n",
    "for p in range(len(axes)):\n",
    "    df_20to50.iloc[os+p*split:os+(p+1)*split:5].plot.bar(stacked=True, ax=axes[p], color = cols)\n",
    "    \n",
    "    axes[p].axes.get_xaxis().set_ticklabels([])\n",
    "    title = 'Every 5th variant, from variant ' + str(os+p*split) + ' to variant ' + str(os+(p+1)*split)\n",
    "    axes[p].set_title(title, position=(0.5, 0.9))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df_50p.append(df_20to50)\n",
    "pos = df_pos.to_dict()\n",
    "df_pos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the final dataset contains any variants with mutations outside the designed positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.Library_diversity import convert_variant_to_dict\n",
    "\n",
    "def n_altered_positions(short):\n",
    "    return len(convert_variant_to_dict(short))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos['short'] = df_pos.index \n",
    "df_pos['nMuts'] = df_pos['short'].apply(n_altered_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos[df_pos['nMuts'] > 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two such variants out of 32400, so we drop those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df_pos.drop(['6L/7aL/9A/9a*', '6L/7aI/9A/9a*'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the filtering steps have been completed: the result is a dataset with 32,4K variants that we are confident to call active MEK1 variants. Next, I use these variants to explore the enrichment of different amino acids amongst positive variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the single mutants in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_2 = ['A', 'Δ']\n",
    "aa_12 = ['A','G','P','Y','D','K','M','V','I','L','F','W']\n",
    "aa_13 = aa_12 +  ['Δ']\n",
    "pos_aa = {'6': aa_12, '9': aa_12, '11': aa_12, '13': aa_12, '7a': aa_13, '8a': aa_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming distance = 0 if the aa matches at all positions\n",
    "def hamming_distance(s1, s2, splimlib):\n",
    "    d = 0\n",
    "    if (len(s1) != len(splimlib)) or (len(s2) != len(splimlib)):\n",
    "        d += 1\n",
    "\n",
    "    for p in splimlib.keys():\n",
    "        if s1[p] != s2[p]:\n",
    "            d += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_short = '6P/9I/11L/13P'\n",
    "wt = {'6': 'P', '7a': 'Δ', '8a': 'Δ', '9': 'I', '11': 'L', '13': 'P'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_vars = df_pos.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_single = 0\n",
    "single_pos_muts = []\n",
    "for short in positive_vars:\n",
    "    s = convert_variant_to_dict(short)\n",
    "    h_dis = hamming_distance(s, wt, wt)\n",
    "    if h_dis in [0,1]:\n",
    "        n_single += 1\n",
    "        single_pos_muts.append(short)\n",
    "print(n_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6: P,I = 2\n",
    "\n",
    "7a: Δ,L,K = 3\n",
    "\n",
    "9: I,P,F = 3\n",
    "\n",
    "11: F,L,M,I = 4\n",
    "\n",
    "13: P,I,L,W,V,F = 6\n",
    "\n",
    "\n",
    "So the max number of additive variants would be 432 variants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*3*3*4*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check what reads distribution is in the other point mutants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, 57 point mutants relative to MKK1 wt sequence are possible. Of those, we observe 13 in the curated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11+12+1+11+11+11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pos_muts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_point_mutant(short):\n",
    "    position_order = ['6', '7a', '8a', '9', '11', '13']\n",
    "    \n",
    "    m_by_pos = convert_variant_to_dict(short)\n",
    "    aa_sequence_shorthand = []\n",
    "    for p in position_order:\n",
    "        if m_by_pos[p] == 'Δ':\n",
    "            aa_sequence_shorthand.append('-')\n",
    "        else:\n",
    "            aa_sequence_shorthand.append(m_by_pos[p])\n",
    "    return ''.join(aa_sequence_shorthand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nice_labels(df):\n",
    "    df['short'] = df.index \n",
    "    df['fig_format'] = df['short'].apply(format_point_mutant)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_high_df = add_nice_labels(df_pos[df_pos.index.isin(single_pos_muts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(3,5))\n",
    "point_high_df.plot.barh(stacked=True, ax=ax, color=cols, \n",
    "                        x='fig_format' ,title='MKK1 point mutants in active dataset')\n",
    "#plt.savefig('Point_mutants_active_h.svg', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(5,3))\n",
    "point_high_df.plot.bar(stacked=True, ax=ax, color=cols, \n",
    "                       x='fig_format', title='MKK1 point mutants in active dataset')\n",
    "#plt.savefig('Point_mutants_active.svg', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variant_is_allowed(m_by_pos, pos_aa):\n",
    "    if len(m_by_pos) != len(pos_aa):\n",
    "        return False\n",
    "    for p, aa in m_by_pos.items():\n",
    "        if aa not in pos_aa[p]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = df_all.index.tolist()\n",
    "\n",
    "n_neg_single = 0\n",
    "single_neg_muts = []\n",
    "for short in all_vars:\n",
    "    s = convert_variant_to_dict(short)\n",
    "    # check that it's not a sequencing error\n",
    "    if not variant_is_allowed(s, pos_aa):\n",
    "        continue\n",
    "    \n",
    "    h_dis = hamming_distance(s, wt, wt)  \n",
    "    if h_dis == 1:\n",
    "        if short not in single_pos_muts:\n",
    "            n_neg_single += 1\n",
    "            single_neg_muts.append(short)\n",
    "            \n",
    "print(n_neg_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(single_neg_muts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_low_df = add_nice_labels(df_all[df_all.index.isin(single_neg_muts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(10,3))\n",
    "point_low_df.plot.bar(stacked=True, ax=ax, color= cols, \n",
    "                      x='fig_format', title='MKK1 low activity point mutants')\n",
    "\n",
    "# plt.xticks(rotation=45)\n",
    "plt.savefig('Point_mutants_inactive.svg', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "57-13-43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That leaves only a single point mutant unaccounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(3,10))\n",
    "point_low_df.plot.barh(stacked=True, ax=ax, color=cols,\n",
    "                       x='fig_format', title='MKK1 low activity point mutants')\n",
    "#plt.savefig('Point_mutants_inactive.svg', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up clean, full dataset for MAVE NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_short = '6P/9I/11L/13P'\n",
    "wt = {'6': 'P', '7a': 'Δ', '8a': 'Δ', '9': 'I', '11': 'L', '13': 'P'}\n",
    "\n",
    "H_dist = {}\n",
    "for n in df_all.index:\n",
    "    s1 = convert_variant_to_dict(n)\n",
    "    H_dist[n] = hamming_distance(wt, s1, splimlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[(lambda df_all: df_all['high'] >= 10) or (lambda df_all: df_all['med'] >= 5) or (lambda df_all: df_all['low-t'] >= 3), :].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df_all.loc[lambda df: df['low-t'] >= 3, :]\n",
    "m = df_all.loc[lambda df: df['med'] >= 5, :]\n",
    "h = df_all.loc[lambda df: df['high'] >= 10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_df = pd.concat([h, m, l], join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_short = '6P/9I/11L/13P'\n",
    "wt = {'6': 'P', '7a': 'Δ', '8a': 'Δ', '9': 'I', '11': 'L', '13': 'P'}\n",
    "\n",
    "H_dist = {}\n",
    "for n in all_filtered_df.index:\n",
    "    s1 = convert_variant_to_dict(n)\n",
    "    H_dist[n] = hamming_distance(wt, s1, splimlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations_all_positions = {}\n",
    "position_order = ['6', '7a', '8a', '9', '11', '13']\n",
    "expected = {}\n",
    "\n",
    "for n in all_filtered_df.index:\n",
    "    s1 = convert_variant_to_dict(n)\n",
    "    expected[n] = is_variant_in_expected_set(s1, splimlib)\n",
    "    aa_seq = [p + s1[p] for p in position_order]\n",
    "    mutations_all_positions[n] = '/'.join(aa_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_variant_in_expected_set(m_by_pos, splimlib):\n",
    "    for k, a in m_by_pos.items():\n",
    "        if k not in splimlib.keys():\n",
    "            return False\n",
    "        elif a not in splimlib[k]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_df['Hamming'] = pd.Series(H_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_df['Name'] = pd.Series(mutations_all_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_df['in_lib'] = pd.Series(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splimlib = all_filtered_df.loc[all_filtered_df['in_lib'] == True].drop(columns=['in_lib']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splimlib.to_csv('MKK1_all_SpliMLiB_variants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splimlib.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
